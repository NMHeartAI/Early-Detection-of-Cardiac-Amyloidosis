{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FIGDST = Path(\"../figures_out/temp_trash\")\n",
    "SAVE_FMT = {\"format\": \"tiff\", \"dpi\": 300}\n",
    "AEQDST = FIGDST / \"aequitas\"\n",
    "plt.style.use(\"seaborn-v0_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cohort = pd.read_parquet(COHORT_DATA_FILE)\n",
    "mask_both = (\n",
    "    main_cohort[\"mayo_score\"].notna()\n",
    "    & main_cohort[\"ultromics_prediction\"].notna()\n",
    "    & main_cohort[\"echonet_prediction\"].notna()\n",
    "    & (main_cohort[\"ultromics_classification\"] != \"Uncertain\")\n",
    ")\n",
    "echonet_matched_cohort = main_cohort.loc[mask_both]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aequitas_cohort__echonet = echonet_matched_cohort.copy(deep=True)\n",
    "aequitas_cohort__echonet.rename(\n",
    "    {\n",
    "        \"echonet_prediction\": \"score\",\n",
    "        \"true_label\": \"label_value\",\n",
    "    },\n",
    "    inplace=True,\n",
    "    axis=1,\n",
    ")\n",
    "aequitas_cohort__echonet[\"model_id\"] = \"EchoNet-LVH\"\n",
    "\n",
    "aequitas_cohort__mayo = echonet_matched_cohort.copy(deep=True)\n",
    "aequitas_cohort__echonet.rename(\n",
    "    {\n",
    "        \"mayo_score\": \"score\",\n",
    "        \"true_label\": \"label_value\",\n",
    "    },\n",
    "    inplace=True,\n",
    "    axis=1,\n",
    ")\n",
    "aequitas_cohort__mayo[\"model_id\"] = \"Mayo ATTR-CM Score\"\n",
    "\n",
    "aequitas_cohort__ult = echonet_matched_cohort.copy(deep=True)\n",
    "aequitas_cohort__echonet.rename(\n",
    "    {\n",
    "        \"ultromics_prediction\": \"score\",\n",
    "        \"true_label\": \"label_value\",\n",
    "    },\n",
    "    inplace=True,\n",
    "    axis=1,\n",
    ")\n",
    "aequitas_cohort__ult[\"model_id\"] = \"EchoGo Amyloidosis\"\n",
    "\n",
    "aequitas_cohort = pd.concat(\n",
    "    [aequitas_cohort__mayo, aequitas_cohort__echonet, aequitas_cohort__ult]\n",
    ")\n",
    "aequitas_cohort[\"SDI\"] = pd.cut(\n",
    "    aequitas_cohort.SDI_score,\n",
    "    [0, 25, 50, 75, 100],\n",
    "    include_lowest=True,\n",
    "    ordered=False,\n",
    "    labels=[0, 1, 2, 3],\n",
    ").astype(str)\n",
    "aequitas_cohort = aequitas_cohort.loc[\n",
    "    aequitas_cohort.Sex.notna()\n",
    "    & aequitas_cohort.SDI.notna()\n",
    "    & aequitas_cohort.Race.notna()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = Group()\n",
    "xtab_raw, temp = group.get_multimodel_crosstabs(\n",
    "    aequitas_cohort,\n",
    "    attr_cols=[\"Sex\", \"Race\"],\n",
    "    score_thresholds={\"score_val\": [6, 0.8, 0.06]},\n",
    ")\n",
    "\n",
    "# Dropping unnecessary (model_id, score_threshold) pairs\n",
    "xtab = xtab_raw.loc[\n",
    "    (\n",
    "        (xtab_raw.model_id == \"Mayo ATTR-CM Score\")\n",
    "        & (xtab_raw.score_threshold == \"6_val\")\n",
    "    )\n",
    "    | ((xtab_raw.model_id == \"EchoNet-LVH\") & (xtab_raw.score_threshold == \"0.8_val\"))\n",
    "    | (\n",
    "        (xtab_raw.model_id == \"EchoGo Amyloidosis\")\n",
    "        & (xtab_raw.score_threshold == \"0.06_val\")\n",
    "    ),\n",
    "    :,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aequitas_plot = Plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in [\"Mayo ATTR-CM Score\", \"EchoNet-LVH\", \"EchoGo Amyloidosis\"]:\n",
    "    temp_fig = aequitas_plot.plot_group_metric_all(\n",
    "        xtab[xtab.model_id == model_id],\n",
    "        metrics=[\n",
    "            \"pprev\",\n",
    "            \"ppr\",\n",
    "            \"fdr\",\n",
    "            \"for\",\n",
    "            \"fpr\",\n",
    "            \"fnr\",\n",
    "            \"tpr\",\n",
    "            \"tnr\",\n",
    "            \"npv\",\n",
    "            \"precision\",\n",
    "        ],\n",
    "    )\n",
    "    temp_fig.tight_layout()\n",
    "    temp_fig.savefig(\n",
    "        AEQDST / f\"{model_id}_absolute_metrics_full.{SAVE_FMT['format']}\", **SAVE_FMT\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = Bias()\n",
    "bias_df = bias.get_disparity_predefined_groups(\n",
    "    xtab,\n",
    "    original_df=aequitas_cohort.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"score\",\n",
    "            \"label_value\",\n",
    "            \"Sex\",\n",
    "            \"Race\",\n",
    "            \"model_id\",\n",
    "        ],\n",
    "    ],\n",
    "    ref_groups_dict={\n",
    "        \"Sex\": \"male\",\n",
    "        \"Race\": \"White\",\n",
    "    },\n",
    "    alpha=0.05,\n",
    "    check_significance=True,\n",
    "    mask_significance=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness = Fairness()\n",
    "fairness_df = fairness.get_group_value_fairness(bias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in [\"Mayo ATTR-CM Score\", \"EchoNet-LVH\", \"EchoGo Amyloidosis\"]:\n",
    "    temp_fig = aequitas_plot.plot_fairness_group_all(\n",
    "        fairness_df[fairness_df.model_id == model_id], metrics=\"all\", ncols=5\n",
    "    )\n",
    "    temp_fig.tight_layout()\n",
    "    temp_fig.savefig(AEQDST / f\"{model_id}_fairness.{SAVE_FMT['format']}\", **SAVE_FMT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in [\"Mayo ATTR-CM Score\", \"EchoNet-LVH\", \"EchoGo Amyloidosis\"]:\n",
    "    fairness_pprev = Fairness(\n",
    "        fair_eval=lambda tau: lambda x: (\n",
    "            np.nan if np.isnan(x) else (True if 0.8 <= x <= np.inf else False)\n",
    "        )\n",
    "    )\n",
    "    fairness_df_pprev = fairness_pprev.get_group_value_fairness(bias_df)\n",
    "    temp_fig = aequitas_plot.plot_fairness_disparity_all(\n",
    "        fairness_df_pprev[fairness_df_pprev.model_id == model_id],\n",
    "        metrics=[\"pprev\"],\n",
    "        show_figure=False,\n",
    "    )\n",
    "    for text in temp_fig.axes[1].texts:\n",
    "        text.set_text(text.get_text().replace(\"**\", \"*\"))\n",
    "        text.set_fontsize(22)\n",
    "    temp_fig.savefig(\n",
    "        AEQDST / f\"{model_id}_pprev_disparity.{SAVE_FMT['format']}\", **SAVE_FMT\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in [\"Mayo ATTR-CM Score\", \"EchoNet-LVH\", \"EchoGo Amyloidosis\"]:\n",
    "    fairness_precision = Fairness(\n",
    "        fair_eval=lambda tau: lambda x: (\n",
    "            np.nan if np.isnan(x) else (True if 0.8 <= x <= np.inf else False)\n",
    "        )\n",
    "    )\n",
    "    fairness_df_precision = fairness_precision.get_group_value_fairness(bias_df)\n",
    "    temp_fig = aequitas_plot.plot_fairness_disparity_all(\n",
    "        fairness_df_precision[fairness_df_precision.model_id == model_id],\n",
    "        metrics=[\"precision\"],\n",
    "        show_figure=False,\n",
    "    )\n",
    "    for text in temp_fig.axes[1].texts:\n",
    "        text.set_text(text.get_text().replace(\"**\", \"*\"))\n",
    "        text.set_fontsize(22)\n",
    "    temp_fig.savefig(\n",
    "        AEQDST / f\"{model_id}_precision_disparity.{SAVE_FMT['format']}\", **SAVE_FMT\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in [\"Mayo ATTR-CM Score\", \"EchoNet-LVH\", \"EchoGo Amyloidosis\"]:\n",
    "    fairness__fnr = Fairness(\n",
    "        fair_eval=lambda tau: lambda x: (\n",
    "            np.nan if np.isnan(x) else (True if 0 <= x <= 1.2 else False)\n",
    "        )\n",
    "    )\n",
    "    fairness_df_fnr = fairness__fnr.get_group_value_fairness(bias_df)\n",
    "    temp_fig = aequitas_plot.plot_fairness_disparity_all(\n",
    "        fairness_df_fnr[fairness_df_fnr.model_id == model_id],\n",
    "        metrics=[\"fnr\"],\n",
    "        show_figure=False,\n",
    "    )\n",
    "    for text in temp_fig.axes[1].texts:\n",
    "        text.set_text(text.get_text().replace(\"**\", \"*\"))\n",
    "        text.set_fontsize(22)\n",
    "    temp_fig.savefig(\n",
    "        AEQDST / f\"{model_id}_fnr_disparity.{SAVE_FMT['format']}\", **SAVE_FMT\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_treeplots import TreePlotConfig, tree_plot\n",
    "\n",
    "config = TreePlotConfig\n",
    "image = tree_plot(\n",
    "    src=Path(\"/home/nea914/projects/aha_risk/figures_out/temp_trash/aequitas\"),\n",
    "    dst=\"/home/nea914/projects/aha_risk/figures_out/temp_trash/disparity_treemap2.tiff\",\n",
    "    config=TreePlotConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic parity refers to positive prediction rate\n",
    "# predictive parity refers to positive predictive value (precision)\n",
    "# equalized opportunity refers to false negative rate\n",
    "\n",
    "common_cols = [\n",
    "    \"model_id\",\n",
    "    \"attribute_value\",\n",
    "    \"group_size\",\n",
    "    \"prev\",\n",
    "    \"tpr\",\n",
    "    \"tnr\",\n",
    "]\n",
    "\n",
    "table6 = pd.concat(\n",
    "    [\n",
    "        fairness_df_pprev.loc[\n",
    "            fairness_df_precision.attribute_name == \"Race\",\n",
    "            common_cols + [\"pprev_disparity\"],\n",
    "        ],\n",
    "        fairness_df_precision.loc[\n",
    "            fairness_df_precision.attribute_name == \"Race\",\n",
    "            [\"precision_disparity\"],\n",
    "        ],\n",
    "        fairness_df_fnr.loc[\n",
    "            fairness_df_precision.attribute_name == \"Race\", [\"fnr_disparity\"]\n",
    "        ],\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_map = {k: v for v, k in enumerate([\"White\", \"Black\", \"Hispanic\", \"Other\"])}\n",
    "for model_id in [\"Mayo ATTR-CM Score\", \"EchoNet-LVH\", \"EchoGo Amyloidosis\"]:\n",
    "    print(\n",
    "        table6[table6.model_id == model_id]\n",
    "        .sort_values(\"attribute_value\", key=lambda x: x.map(race_map))\n",
    "        .round(2)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amyl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
